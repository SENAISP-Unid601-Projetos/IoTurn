# predict.py

import joblib
import pandas as pd
import numpy as np
import hdbscan
import os

# --- 1. FUN√á√ïES PARA CARREGAR OS ARTEFATOS ---

def find_latest_artifacts(artifacts_dir="artifacts"):
    """Encontra os caminhos para o scaler e o modelo mais recentes."""
    try:
        # Lista todos os subdiret√≥rios (vers√µes) na pasta de artefatos
        all_versions = os.listdir(artifacts_dir)
        all_versions.sort() # Ordena para que a vers√£o mais recente fique por √∫ltimo
        
        latest_version_dir = all_versions[-1]
        
        scaler_path = os.path.join(artifacts_dir, latest_version_dir, "scaler.joblib")
        model_path = os.path.join(artifacts_dir, latest_version_dir, "model.joblib")
        
        if os.path.exists(scaler_path) and os.path.exists(model_path):
            print(f"‚úÖ Artefatos mais recentes encontrados em: {latest_version_dir}")
            return scaler_path, model_path
        else:
            print(f"‚ùå Erro: Arquivos 'scaler.joblib' ou 'model.joblib' n√£o encontrados no diret√≥rio: {latest_version_dir}")
            return None, None
            
    except (IndexError, FileNotFoundError):
        print(f"‚ùå Erro: Nenhum artefato de modelo encontrado no diret√≥rio '{artifacts_dir}'.")
        print("Certifique-se de que voc√™ j√° treinou o modelo primeiro.")
        return None, None

def load_artifacts(scaler_path, model_path):
    """Carrega o scaler e o modelo a partir dos caminhos especificados."""
    try:
        scaler = joblib.load(scaler_path)
        model = joblib.load(model_path)
        print("‚úÖ Scaler e Modelo carregados com sucesso.")
        return scaler, model
    except Exception as e:
        print(f"‚ùå Erro ao carregar os artefatos: {e}")
        return None, None

# --- 2. FUN√á√ÉO PRINCIPAL DE PREDI√á√ÉO ---

def predict_regime(scaler, model, new_data_df):
    """
    Prev√™ o regime (cluster) para um novo conjunto de dados.

    Args:
        scaler: O objeto StandardScaler treinado e carregado.
        model: O objeto HDBSCAN treinado e carregado.
        new_data_df: Um DataFrame do Pandas com os novos dados.
                     Deve conter as mesmas colunas num√©ricas do treinamento.

    Returns:
        Um DataFrame com os dados originais e as colunas de predi√ß√£o adicionadas.
    """
    # Verifica√ß√£o de seguran√ßa para garantir que o modelo foi treinado corretamente
    if not hasattr(model, 'prediction_data_'):
        raise TypeError(
            "O modelo HDBSCAN n√£o foi treinado com 'prediction_data=True'. "
            "N√£o √© poss√≠vel fazer predi√ß√µes. Treine o modelo novamente."
        )

    print("üîç Realizando pr√©-processamento e predi√ß√£o do novo dado...")
    
    # Extrai apenas as features num√©ricas na ordem correta
    numeric_features = ['current', 'rpm', 'oilTemperature', 'oilLevel']
    X_new = new_data_df[numeric_features].values

    # Passo 1: Normaliza os novos dados USANDO O SCALER J√Å TREINADO.
    # NUNCA use .fit_transform() em novos dados, apenas .transform()!
    X_scaled = scaler.transform(X_new)

    # Passo 2: Usa a fun√ß√£o approximate_predict
    # Ela espera o modelo treinado e os novos dados normalizados.
    labels, strengths = hdbscan.approximate_predict(model, X_scaled)
    # Adiciona os resultados ao DataFrame original para um retorno claro
    result_df = new_data_df.copy()
    result_df['predicted_cluster'] = labels
    result_df['prediction_strength'] = strengths # A "certeza" da predi√ß√£o (0.0 a 1.0)

    print("‚úÖ Predi√ß√£o conclu√≠da.")
    return result_df

# --- 3. BLOCO DE EXECU√á√ÉO PARA TESTE ---

if __name__ == "__main__":
    # 1. Encontra e carrega os artefatos mais recentes
    scaler_path, model_path = find_latest_artifacts()
    
    if scaler_path and model_path:
        scaler, model = load_artifacts(scaler_path, model_path)

        if scaler and model:
            # 2. Cria exemplos de novos dados para testar a predi√ß√£o
            # IMPORTANTE: Os nomes das colunas devem ser os mesmos do treinamento!
            sample_data = pd.DataFrame([
                # --- Cen√°rio 1: Explorando o Cluster de "Opera√ß√£o Normal" (Cluster 1) ---
                # Hip√≥tese: Deve ser classificado como Cluster 1, com for√ßa decrescente.
                {'current': 19.7, 'rpm': 1590, 'oilTemperature': 79.5, 'oilLevel': 71.5},  # Ponto A: Quase perfeito, no centro do cluster.
                {'current': 30.0, 'rpm': 1800, 'oilTemperature': 90.0, 'oilLevel': 75.0},  # Ponto B: Um pouco mais de carga, mas ainda dentro do esperado.
                {'current': 45.0, 'rpm': 2500, 'oilTemperature': 95.0, 'oilLevel': 68.0},  # Ponto C: No limite do normal. Pode ser Cluster 1 com baixa for√ßa, ou -1.

                # --- Cen√°rio 2: Explorando o Cluster "M√°quina Desligada" (Cluster 0) ---
                # Hip√≥tese: Deve ser classificado como Cluster 0.
                {'current': 4.5,  'rpm': 0,    'oilTemperature': 35.0, 'oilLevel': 72.5},  # Varia√ß√£o do estado ocioso.

                # --- Cen√°rio 3: Tentando encontrar um poss√≠vel cluster de "Partida" ---
                # Hip√≥tese: Pode ser um cluster pequeno que existe (ex: Cluster 2), ou ser -1.
                {'current': 55.0, 'rpm': 350,  'oilTemperature': 48.0, 'oilLevel': 71.0},  # Uma partida menos agressiva que o teste anterior.

                # --- Cen√°rio 4: Anomalias "Sutis" ---
                # Hip√≥tese: Deve ser classificado como -1, pois um par√¢metro est√° fora do normal.
                {'current': 20.0, 'rpm': 1600, 'oilTemperature': 125.0, 'oilLevel': 71.0}, # Opera√ß√£o normal, mas com superaquecimento.
                {'current': 21.0, 'rpm': 1550, 'oilTemperature': 80.0,  'oilLevel': 55.0}, # Opera√ß√£o normal, mas com n√≠vel de √≥leo perigosamente baixo.
            ])

            # 3. Faz a predi√ß√£o
            predictions = predict_regime(scaler, model, sample_data)

            print("\n--- Resultados da Predi√ß√£o ---")
            print(predictions)